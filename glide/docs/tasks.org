* TODO Project Plan :: DREAM function prediction pipeline [83%]
** DONE Parse DREAM networks
   - DREAM networks consist of adjacency lists with proteins listed as
     nodes.
   - Need to decide how I'm going to load the networks for processing. 
   - I should keep the node names with their indices so it is easy to
     attach labels for scoring.
   - Ensure everything is *deanonymized*. Keep it simple.

** DONE Parse GO labels [33%]
We need to load the labels for the nodes. There should be a standard
way to keep the labels with the nodes to ensure that scoring is easy.
which labels are kept is another problem of concern. Currently,
I use all labels for the nodes and the labels are stored in the format

GO_LABEL1 PROTEIN1 PROTEIN2 PROTEIN3 ..
GO_LABEL2 PROTEIN1 PROTEIN2 PROTEIN3 ..

*** TODO Decide on which labels to keep
*** DONE Load raw labels from FA file

** DONE Implement network denoising algorithm(s) [100%]
*** DONE Implement DSD denoising algorithm
*** DONE Implement identity denoising algorithm
*** DONE Implement NE denoising algorithm [66%]
**** DONE Reproduce scoring on raw butterfly network.
**** DONE Port over denoising algorithm.
**** TODO Implement zero handling strategy.
** DONE Implement scoring strategy
*** DONE k-fold cross validation algorithm

** DONE Create a program that takes in a graph, embedding -> functional labelling
   Does this based on the l2 distance induced by the embedding. DSD
   embedding. [[https://github.com/kap-devkota/Trimming_Functional/blob/master/src/Utils/dse_computations.py][Embedding Code]]: DSD embedding compute_X_normalized(...).
*** DONE : Created a program that takes in graph, produces embedding and returns the similarity matrix. Example in `DREAM Network Testbench`

** DONE (Henri) Added the embedding and similarity matrix producing code in `DREAM Network Testbench` notebook. Need to compute a    function that takes in similarity matrix and produces a function label score.
** TODO (Henri) Test function prediction against the network enhancement algorithm
** TODO (Henri/Kapil) Set up SLURM repository for collaboration
What I would like is a repository somewhere on the cluster that is
extremely organized for all of our slurm scripts/python scripts that
test various parameters. It should *not* have any core code (like your
GLIDE method).

There should be top-level module that imports all of our code and then
we can use that in all of our one-off python scripts. Then, there
should be a place for the SLURM code that calls the python scripts.

For the data directory, it would be useful to have some sort of
organization so things don't become too chaotic. Maybe a README
in each directory describing what everything is. Also for
very temporary stuff we can use a /temp directory
** DONE (Henri) Try different voting methods (KNN, WMV)
** DONE (Henri) Try other kernels besides RBF kernel
   Don't waste time tinkering with continuous kernels.
** DONE (Kapil) Create small datasets for us to work on.
** DONE (Kapil) Write up GLIDE code.
